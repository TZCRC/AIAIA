{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note book to create detections over chips for visualzation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import makedirs, path as op\n",
    "from itertools import zip_longest\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "import skimage.io as sio\n",
    "from skimage.transform import rescale\n",
    "import click\n",
    "from tqdm import tqdm\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy scikit-image setuptools -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grouper(iterable, n, fillvalue=None):\n",
    "    \"Itertool recipe to collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "def _filter_pred_keys(pred_dict, keep_keys=('detection_scores',\n",
    "                                            'detection_classes',\n",
    "                                            'detection_boxes')):\n",
    "    \"\"\"Apply filter to keep a limited number of dict keys\"\"\"\n",
    "    new_pred_dict = {}\n",
    "    for key in keep_keys:\n",
    "        new_pred_dict[key] = pred_dict[key]\n",
    "\n",
    "    return new_pred_dict\n",
    "\n",
    "\n",
    "def _apply_score_thresh(pred_dict, score_thresh):\n",
    "    \"\"\"Remove predictions below some score threshold\"\"\"\n",
    "\n",
    "    new_pred_dict = {}\n",
    "    good_inds = np.asarray(pred_dict['detection_scores']) >= score_thresh\n",
    "\n",
    "    for key in pred_dict.keys():\n",
    "        new_pred_dict[key] = np.asarray(pred_dict[key])[good_inds].tolist()\n",
    "\n",
    "    return new_pred_dict\n",
    "\n",
    "def local_inf(image_directory, url_endpoint, save_directory, score_thresh,\n",
    "              batch_size):\n",
    "    \"\"\"Run inference on local directory using TF Serving image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_directory: str\n",
    "        String specifiying the directory path where all images will be inferred\n",
    "    url_endpoint: str\n",
    "        URL of running server (e.g., TF Serving container) where images will\n",
    "        be sent for inference.\n",
    "    save_directory: str\n",
    "        Directory to save predictions. Defaults to same directory as images.\n",
    "    score_thresh: float\n",
    "        Minimum score to include a model detection in the final results.\n",
    "    batch_size: int\n",
    "        Number of images per inference batch. Defaults to 1.\n",
    "    img_ext: list of str\n",
    "        Extensions of files to run prediction on. Defaults to `jpg`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not op.isdir(save_directory):\n",
    "        makedirs(save_directory)\n",
    "        \n",
    "    if not 0. < score_thresh <= 1.:\n",
    "        raise ValueError('`score_thresh` must fall on interval (0, 1]')\n",
    "\n",
    "    img_fnames = [img_fname for img_fname in os.listdir(image_directory) if img_fname.endswith('.jpg')]\n",
    "\n",
    "    # Iterate through groups of images\n",
    "    for img_group in tqdm(_grouper(img_fnames, batch_size)):\n",
    "        print(img_group)\n",
    "\n",
    "        ###################################\n",
    "        # Create a batch of data to predict\n",
    "\n",
    "        instances = []\n",
    "        for batch_img_fname in img_group:\n",
    "            if batch_img_fname is not None:\n",
    "                print(batch_img_fname)\n",
    "                with open(op.join(image_directory, batch_img_fname), 'rb') as image_file:\n",
    "                    b64_image = base64.b64encode(image_file.read())\n",
    "                    instances.append({'inputs': {'b64': b64_image.decode('utf-8')}})\n",
    "                    #instances.append({'inputs': b64_image.decode('utf-8')})\n",
    "\n",
    "        ################\n",
    "        # Run prediction\n",
    "        payload = json.dumps({\"instances\": instances})\n",
    "        resp = requests.post(url_endpoint, data=payload)\n",
    "        print(resp)\n",
    "        print(resp.content)\n",
    "\n",
    "#         preds = json.loads(resp.content)['predictions']\n",
    "#         print(preds)\n",
    "#         ##########################################\n",
    "#         # Save results to text file for each image\n",
    "\n",
    "#         for batch_img_fname, pred_dict in zip(img_group, preds):\n",
    "#             save_fname = op.splitext(batch_img_fname)[0] + '.json'\n",
    "\n",
    "#             # Remove some keys, and then apply score threshold\n",
    "#             pred_dict = _filter_pred_keys(pred_dict)\n",
    "#             pred_dict = _apply_score_thresh(pred_dict, score_thresh)\n",
    "#             pred_dict['image_fname'] = batch_img_fname  # Add filename\n",
    "\n",
    "#             # Save to disk\n",
    "#             with open(op.join(save_directory, save_fname), 'w') as json_file:\n",
    "#                 json.dump(pred_dict, json_file)\n",
    "                \n",
    "                \n",
    "def save_annotated_image(json_fpath, cat_pbtxt_fpath, source_directory,\n",
    "                         save_directory='.', rescale_factor=1.):\n",
    "    \"\"\"Save bounding box predictions as annotations on an image\"\"\"\n",
    "\n",
    "    # Load JSON of image predictions and class indicies\n",
    "    jsons = [op.join(json_fpath, json_) for json_ in os.listdir(json_fpath)]\n",
    "    for json_ in jsons: \n",
    "        with open(json_, 'r') as json_file:\n",
    "            pred = json.load(json_file)\n",
    "\n",
    "        cat_index = label_map_util.create_category_index_from_labelmap(\n",
    "            cat_pbtxt_fpath, use_display_name=True)\n",
    "\n",
    "        # Generate file paths to save/load image\n",
    "        img_fname = op.splitext(op.basename(json_))[0] + '.jpg'\n",
    "        img_load_fpath = op.join(source_directory, img_fname)\n",
    "        img_save_fpath = op.join(save_directory, img_fname)\n",
    "\n",
    "        # Load image and rescale if necessary\n",
    "        image_np = sio.imread(img_load_fpath)\n",
    "        if rescale_factor != 1.:\n",
    "            image_np = rescale(image_np, anti_aliasing=True, multichannel=True,\n",
    "                               scale=rescale_factor, clip=False)\n",
    "    #         image_np = img_as_ubyte(image_np)\n",
    "\n",
    "        # Increase font size\n",
    "        # Move arial.ttf to /models/research/object_detection/utils\n",
    "        #font = ImageFont.truetype('./arial.ttc', 36)\n",
    "\n",
    "        # Visualization of the results of a detection.\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            np.asarray(pred['detection_boxes']),\n",
    "            np.asarray(pred['detection_classes'], dtype=np.uint8),\n",
    "            np.asarray(pred['detection_scores']),\n",
    "            cat_index,\n",
    "            instance_masks=pred.get('detection_masks'),\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=1)\n",
    "\n",
    "        # Save output; time-consuming for large images\n",
    "        sio.imsave(img_save_fpath, image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('wcm_n51_L_20190602095310_0_0.jpg', 'wcm_n51_L_20190602095310_0_2.jpg', 'wcm_n51_L_20190602095310_0_3.jpg', 'wcm_n51_L_20190602095310_0_4.jpg', 'wcm_n51_L_20190602095310_0_5.jpg')\n",
      "wcm_n51_L_20190602095310_0_0.jpg\n",
      "wcm_n51_L_20190602095310_0_2.jpg\n",
      "wcm_n51_L_20190602095310_0_3.jpg\n",
      "wcm_n51_L_20190602095310_0_4.jpg\n",
      "wcm_n51_L_20190602095310_0_5.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_0_6.jpg', 'wcm_n51_L_20190602095310_0_7.jpg', 'wcm_n51_L_20190602095310_0_8.jpg', 'wcm_n51_L_20190602095310_0_9.jpg', 'wcm_n51_L_20190602095310_10_0.jpg')\n",
      "wcm_n51_L_20190602095310_0_6.jpg\n",
      "wcm_n51_L_20190602095310_0_7.jpg\n",
      "wcm_n51_L_20190602095310_0_8.jpg\n",
      "wcm_n51_L_20190602095310_0_9.jpg\n",
      "wcm_n51_L_20190602095310_10_0.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_10_1.jpg', 'wcm_n51_L_20190602095310_10_2.jpg', 'wcm_n51_L_20190602095310_10_3.jpg', 'wcm_n51_L_20190602095310_10_4.jpg', 'wcm_n51_L_20190602095310_10_5.jpg')\n",
      "wcm_n51_L_20190602095310_10_1.jpg\n",
      "wcm_n51_L_20190602095310_10_2.jpg\n",
      "wcm_n51_L_20190602095310_10_3.jpg\n",
      "wcm_n51_L_20190602095310_10_4.jpg\n",
      "wcm_n51_L_20190602095310_10_5.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_10_6.jpg', 'wcm_n51_L_20190602095310_10_7.jpg', 'wcm_n51_L_20190602095310_10_8.jpg', 'wcm_n51_L_20190602095310_10_9.jpg', 'wcm_n51_L_20190602095310_11_0.jpg')\n",
      "wcm_n51_L_20190602095310_10_6.jpg\n",
      "wcm_n51_L_20190602095310_10_7.jpg\n",
      "wcm_n51_L_20190602095310_10_8.jpg\n",
      "wcm_n51_L_20190602095310_10_9.jpg\n",
      "wcm_n51_L_20190602095310_11_0.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_11_1.jpg', 'wcm_n51_L_20190602095310_11_2.jpg', 'wcm_n51_L_20190602095310_11_3.jpg', 'wcm_n51_L_20190602095310_11_4.jpg', 'wcm_n51_L_20190602095310_11_5.jpg')\n",
      "wcm_n51_L_20190602095310_11_1.jpg\n",
      "wcm_n51_L_20190602095310_11_2.jpg\n",
      "wcm_n51_L_20190602095310_11_3.jpg\n",
      "wcm_n51_L_20190602095310_11_4.jpg\n",
      "wcm_n51_L_20190602095310_11_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_11_6.jpg', 'wcm_n51_L_20190602095310_11_7.jpg', 'wcm_n51_L_20190602095310_11_8.jpg', 'wcm_n51_L_20190602095310_11_9.jpg', 'wcm_n51_L_20190602095310_12_0.jpg')\n",
      "wcm_n51_L_20190602095310_11_6.jpg\n",
      "wcm_n51_L_20190602095310_11_7.jpg\n",
      "wcm_n51_L_20190602095310_11_8.jpg\n",
      "wcm_n51_L_20190602095310_11_9.jpg\n",
      "wcm_n51_L_20190602095310_12_0.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_12_1.jpg', 'wcm_n51_L_20190602095310_12_2.jpg', 'wcm_n51_L_20190602095310_12_3.jpg', 'wcm_n51_L_20190602095310_12_4.jpg', 'wcm_n51_L_20190602095310_12_5.jpg')\n",
      "wcm_n51_L_20190602095310_12_1.jpg\n",
      "wcm_n51_L_20190602095310_12_2.jpg\n",
      "wcm_n51_L_20190602095310_12_3.jpg\n",
      "wcm_n51_L_20190602095310_12_4.jpg\n",
      "wcm_n51_L_20190602095310_12_5.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_12_6.jpg', 'wcm_n51_L_20190602095310_12_7.jpg', 'wcm_n51_L_20190602095310_12_8.jpg', 'wcm_n51_L_20190602095310_12_9.jpg', 'wcm_n51_L_20190602095310_13_0.jpg')\n",
      "wcm_n51_L_20190602095310_12_6.jpg\n",
      "wcm_n51_L_20190602095310_12_7.jpg\n",
      "wcm_n51_L_20190602095310_12_8.jpg\n",
      "wcm_n51_L_20190602095310_12_9.jpg\n",
      "wcm_n51_L_20190602095310_13_0.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_13_1.jpg', 'wcm_n51_L_20190602095310_13_2.jpg', 'wcm_n51_L_20190602095310_13_3.jpg', 'wcm_n51_L_20190602095310_13_4.jpg', 'wcm_n51_L_20190602095310_13_5.jpg')\n",
      "wcm_n51_L_20190602095310_13_1.jpg\n",
      "wcm_n51_L_20190602095310_13_2.jpg\n",
      "wcm_n51_L_20190602095310_13_3.jpg\n",
      "wcm_n51_L_20190602095310_13_4.jpg\n",
      "wcm_n51_L_20190602095310_13_5.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_13_7.jpg', 'wcm_n51_L_20190602095310_13_8.jpg', 'wcm_n51_L_20190602095310_13_9.jpg', 'wcm_n51_L_20190602095310_14_1.jpg', 'wcm_n51_L_20190602095310_14_2.jpg')\n",
      "wcm_n51_L_20190602095310_13_7.jpg\n",
      "wcm_n51_L_20190602095310_13_8.jpg\n",
      "wcm_n51_L_20190602095310_13_9.jpg\n",
      "wcm_n51_L_20190602095310_14_1.jpg\n",
      "wcm_n51_L_20190602095310_14_2.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n",
      "('wcm_n51_L_20190602095310_14_3.jpg', 'wcm_n51_L_20190602095310_14_4.jpg', 'wcm_n51_L_20190602095310_14_5.jpg', None, None)\n",
      "wcm_n51_L_20190602095310_14_3.jpg\n",
      "wcm_n51_L_20190602095310_14_4.jpg\n",
      "wcm_n51_L_20190602095310_14_5.jpg\n",
      "<Response [400]>\n",
      "b'{ \"error\": \"Attempting to use uninitialized value FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights\\\\n\\\\t [[{{node FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/read}}]]\" }'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_directory = 'data/cormon2019_chips'\n",
    "\n",
    "#Get ip addrees docker network inspect ai4earth-wildlife-conservation_default\n",
    "\n",
    "server_endpoint = 'http://172.23.0.1:8501/v1/models/wildlife:predict'\n",
    "# r = requests.get(server_endpoint)\n",
    "# print(r)\n",
    "\n",
    "score_thresh = 0.5\n",
    "batch_size = 5\n",
    "directory = \"data/cormon2019_chips_local_inf\"\n",
    "local_inf(image_directory, server_endpoint, directory, score_thresh,batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #building parts \n",
    "# json_fpath = \"building_parts_dir_local_inf\"\n",
    "# cat_pbtxt_fpath = 'building_parts.pbtxt'\n",
    "# source_directory = \"gif_creation_local_inference\"\n",
    "# save_directory = json_fpath\n",
    "# save_annotated_image(json_fpath, cat_pbtxt_fpath, source_directory,\n",
    "#                          save_directory, rescale_factor=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building properties\n",
    "# json_fpath = \"building_properties_dir_local_inf\"\n",
    "# cat_pbtxt_fpath = 'building_properties-padang.pbtxt'\n",
    "# source_directory = \"gif_creation_local_inference\"\n",
    "# save_directory = json_fpath\n",
    "# save_annotated_image(json_fpath, cat_pbtxt_fpath, source_directory,\n",
    "#                          save_directory, rescale_factor=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
